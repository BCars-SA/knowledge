# API Server Configuration
PORT=3000
HOST=0.0.0.0
API_KEY=test-api-key

# CORS Configuration
CORS_ORIGIN=http://localhost:3000,http://localhost:3001
CORS_CREDENTIALS=true
CORS_METHODS=GET,POST,PUT,DELETE,OPTIONS

# Rate Limiting Configuration
RATE_LIMIT_WINDOW_MS=900000
RATE_LIMIT_MAX_REQUESTS=100
RATE_LIMIT_SKIP_SUCCESSFUL=false

# Logging Configuration
LOG_LEVEL=debug
LOG_CONSOLE_ENABLED=true
LOG_CONSOLE_COLORIZE=true
LOG_FILE_ENABLED=false
LOG_FILE_NAME=prod.log
LOG_FILE_MAX_SIZE=10m
LOG_FILE_MAX_FILES=5

# Common LLM
LLM_COMMON_PROVIDER=vertexai
LLM_COMMON_MODEL=gemini-2.5-flash
LLM_COMMON_MAX_TOKENS=2048
LLM_COMMON_HEADERS_HTTP_REFERER=https://my-super-service.com
LLM_COMMON_HEADERS_X_TITLE=DEV:MY SUPER SERVICE: Common
# VertexAI specific vars (west2 - London, the best throughput for Europe)
LLM_COMMON_LOCATION=europe-west2
LLM_COMMON_THINKING_BUDGET=0

# LLM GLOBAL KEYS
GOOGLE_APPLICATION_CREDENTIALS=google-app-credentials.json


# Postgres
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_USER=postgres
POSTGRES_PASSWORD=test
POSTGRES_DB=postgres

REDIS_HOST=localhost
REDIS_PORT=6379
#REDIS_PASSWORD=test
REDIS_DB=0
REDIS_MAX_RETRIES=3

# Cache TTL Configuration

# Database Pool Configuration
DB_POOL_MIN=2
DB_POOL_MAX=20
DB_POOL_IDLE_TIMEOUT=30000